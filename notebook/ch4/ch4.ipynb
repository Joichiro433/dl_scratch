{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネットワークの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "import os\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nptyping import NDArray\n",
    "from IPython.display import display\n",
    "from rich import print as rprint\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "colors = ['#de3838', '#007bc3', '#ffd12a']\n",
    "markers = ['o', 'x', ',']\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 100)\n",
    "\n",
    "cmap = sns.diverging_palette(255, 0, as_cmap=True)  # カラーパレットの定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09750000000000003\n",
      "0.5975\n"
     ]
    }
   ],
   "source": [
    "def sum_squared_error(y: NDArray[float], t: NDArray[int]) -> NDArray[float]:\n",
    "    return 0.5 * np.sum((y - t)**2)\n",
    "\n",
    "t = np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
    "y = np.array([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0])\n",
    "print(sum_squared_error(y, t))\n",
    "\n",
    "t = np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
    "y = np.array([0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0])\n",
    "print(sum_squared_error(y, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.510825457099338\n",
      "2.3025840929945454\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy_error(y: NDArray[float], t: NDArray[int]) -> NDArray[float]:\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))\n",
    "\n",
    "t = np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
    "y = np.array([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0])\n",
    "print(cross_entropy_error(y, t))\n",
    "\n",
    "t = np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
    "y = np.array([0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0])\n",
    "print(cross_entropy_error(y, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ミニバッチ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "train_images = train_images.reshape(60000, 784) / 255\n",
    "test_images = test_images.reshape(10000, 784) / 255\n",
    "\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41942 59761 23465 25385 45278 13608 57452 14447 46652 24498]\n"
     ]
    }
   ],
   "source": [
    "train_size = train_images.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask : NDArray[(batch_size,), int] = np.random.choice(train_size, batch_size)\n",
    "print(batch_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y: NDArray[int], t: NDArray[int]) -> float:\n",
    "    \"\"\"クロスエントロピー誤差\n",
    "\n",
    "    UnitTests\n",
    "    ---------\n",
    "    >>> cross_entropy_error(np.array([1, 0, 0]), np.array([0, 1, 0]))\n",
    "    16.118095650958317\n",
    "    >>> cross_entropy_error(np.array([[1, 0, 0], [0, 0, 1]]), np.array([[0, 1, 0], [0, 0, 1]]))\n",
    "    8.059047775479161\n",
    "    >>> cross_entropy_error(np.array([[1, 0, 0], [0, 0, 1]]), np.array([1, 2]))\n",
    "    8.059047775479161\n",
    "    \"\"\"\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 教師データがone-hot-vectorの場合、正解ラベルのインデックスに変換\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 勾配法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient_1d(\n",
    "        func: Callable[[NDArray[float]], float], \n",
    "        x: NDArray[float]) -> NDArray[float]:\n",
    "    \"\"\"数値微分(1d_array専用)\n",
    "\n",
    "    UnitTests\n",
    "    ---------\n",
    "    >>> numerical_gradient(lambda x: x[0]**2+x[1]**2, np.array([3.0, 4.0]))\n",
    "    array([6., 8.])\n",
    "    \"\"\"\n",
    "    delta_x : float = 1e-4\n",
    "    grad : NDArray[float] = np.zeros_like(x)\n",
    "    for idx in range(x.size):\n",
    "        temp : float = x[idx]\n",
    "        x[idx] = temp + delta_x\n",
    "        func_x1 : float = func(x)\n",
    "        x[idx] = temp - delta_x\n",
    "        func_x2 : float = func(x)\n",
    "        grad[idx] = (func_x1 - func_x2) / (2*delta_x)\n",
    "        x[idx] = temp\n",
    "    return grad\n",
    "\n",
    "\n",
    "def numerical_gradient(\n",
    "        func: Callable[[NDArray[float]], float], \n",
    "        x: NDArray[float]) -> NDArray[float]:\n",
    "    delta_x : float = 1e-4\n",
    "    grad : NDArray[float] = np.zeros_like(x)\n",
    "    it : np.nditer = np.nditer(x, flags=['multi_index'])\n",
    "    while not it.finished:\n",
    "        idx : Tuple[int, ...] = it.multi_index\n",
    "        temp : float = x[idx]\n",
    "        x[idx] = temp + delta_x\n",
    "        func_x1 : float = func(x)  # f(x+Δx)\n",
    "        x[idx] = temp - delta_x\n",
    "        func_x2 : float = func(x)  # f(x-Δx)\n",
    "        grad[idx] = (func_x1 - func_x2) / (2*delta_x)\n",
    "        x[idx] = temp\n",
    "        it.iternext()\n",
    "    return grad\n",
    "\n",
    "\n",
    "def gradient_descent(\n",
    "        func: Callable[[NDArray[float]], float],\n",
    "        init_x: NDArray[float], \n",
    "        lr: float = 0.01, \n",
    "        num_steps : int = 1000) -> NDArray[float]:\n",
    "    \"\"\"勾配降下法\n",
    "\n",
    "    UnitTests\n",
    "    ---------\n",
    "    >>> gradient_descent(lambda x: x[0]**2+x[1]**2, np.array([-3.0, 4.0]))\n",
    "    array([-5.04890207e-09,  6.73186943e-09])\n",
    "    \"\"\"\n",
    "    x : NDArray[float] = init_x\n",
    "    for _ in range(num_steps):\n",
    "        grad : NDArray[float] = numerical_gradient(func=func, x=x)\n",
    "        x -= lr * grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネットワークに対する勾配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">重みパラメータ\n",
       " <span style=\"font-weight: bold\">[[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.49671415</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1382643</span>   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.64768854</span><span style=\"font-weight: bold\">]</span>\n",
       " <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.52302986</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.23415337</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.23413696</span><span style=\"font-weight: bold\">]]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "重みパラメータ\n",
       " \u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m0.49671415\u001b[0m \u001b[1;36m-0.1382643\u001b[0m   \u001b[1;36m0.64768854\u001b[0m\u001b[1m]\u001b[0m\n",
       " \u001b[1m[\u001b[0m \u001b[1;36m1.52302986\u001b[0m \u001b[1;36m-0.23415337\u001b[0m \u001b[1;36m-0.23413696\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">予測値: <span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.66875536</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.29369662</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.17788986</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "予測値: \u001b[1m[\u001b[0m \u001b[1;36m1.66875536\u001b[0m \u001b[1;36m-0.29369662\u001b[0m  \u001b[1;36m0.17788986\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z shape (3,)\n",
      "softmax(Z) shape (3,)\n",
      "softmax(Z) shape 1\n",
      "loss: 1.802525525796413\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))    \n",
    "\n",
    "def softmax(x: NDArray) -> NDArray:\n",
    "    x = x - np.max(x, axis=-1, keepdims=True)\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=-1, keepdims=True)\n",
    "\n",
    "def cross_entropy_error(y: NDArray, t: NDArray) -> float:\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    if t.ndim == y.ndim:  # tがone-hot-vectorの場合、正解ラベルのindexに変換\n",
    "        t = t.argmax(axis=1)\n",
    "    \n",
    "    batch_size : int = y.shape[0]\n",
    "    epsilon = 1e-7\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + epsilon)) / batch_size\n",
    "\n",
    "SampleSize = 1\n",
    "InputSize = 2\n",
    "OutputSize = 3\n",
    "\n",
    "class SimpleNN:\n",
    "    def __init__(self) -> None:\n",
    "        np.random.seed(seed=42)\n",
    "        self.W : NDArray[(InputSize, OutputSize), float] = np.random.randn(2, 3)  # ガウス分布で初期化\n",
    "\n",
    "    def predict(self, x: NDArray[(1, InputSize), float]) -> NDArray[(1, OutputSize), float]:\n",
    "        return x @ self.W\n",
    "\n",
    "    def loss(self, x: NDArray[(1, InputSize), float], t: NDArray[(OutputSize), float]) -> float:\n",
    "        Z : NDArray[(1, OutputSize), float] = self.predict(x)\n",
    "        print('Z shape', Z.shape)\n",
    "        print('softmax(Z) shape', softmax(Z).shape)\n",
    "        print('softmax(Z) shape', softmax(Z).ndim)\n",
    "        Y : NDArray[(1, OutputSize), float] = softmax(Z)\n",
    "        loss : float = cross_entropy_error(Y, t)\n",
    "        return loss\n",
    "\n",
    "\n",
    "snn : SimpleNN = SimpleNN()\n",
    "rprint('重みパラメータ\\n', snn.W)\n",
    "# x = np.array([[0.6, 0.9]])\n",
    "x = np.array([0.6, 0.9])\n",
    "p : NDArray[(OutputSize), float] = snn.predict(x=x)\n",
    "rprint('予測値:', p)\n",
    "t = np.array([0, 0, 1])  # 正解ラベル\n",
    "print('loss:', snn.loss(x, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2層ニューラルネットワーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleSize = 0\n",
    "InputSize = 0\n",
    "HiddenSize = 0\n",
    "OutputSize = 0\n",
    "\n",
    "\n",
    "class TowLayerNN:\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int, weight_init_std: float = 0.01) -> None:\n",
    "        # 重みを正規乱数で初期化\n",
    "        self.params : Dict[str, NDArray] = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "    def predict(self, x: NDArray[(SampleSize, InputSize)]) -> NDArray[(SampleSize, OutputSize)]:\n",
    "        W1 : NDArray[(InputSize, HiddenSize)] = self.params['W1']\n",
    "        W2 : NDArray[(OutputSize, HiddenSize)] = self.params['W2']\n",
    "        b1 : NDArray[(HiddenSize)] = self.params['b1']\n",
    "        b2 : NDArray[(OutputSize)] = self.params['b2']\n",
    "\n",
    "        Z1 : NDArray[(SampleSize, HiddenSize)] = sigmoid(x @ W1 + b1)\n",
    "        Y : NDArray[(SampleSize, OutputSize)] = sigmoid(Z1 @ W2 + b2)\n",
    "        return Y\n",
    "\n",
    "    def loss(self, x: NDArray[(SampleSize, InputSize)], t) -> float:\n",
    "        y : NDArray[(SampleSize, OutputSize)] = self.predict(x)\n",
    "        return cross_entropy_error(y, t)\n",
    "\n",
    "    def accuracy(self, x: NDArray[(SampleSize, InputSize)], t) -> float:\n",
    "        y : NDArray[(SampleSize, OutputSize)] = self.predict(x)\n",
    "        y : NDArray[(SampleSize)] = np.argmax(y, axis=1)\n",
    "        t : NDArray[(SampleSize)] = np.argmax(t, axis=1)\n",
    "        accuracy : float = np.sum(y==t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "\n",
    "    def numerical_gradient(self, x: NDArray[(SampleSize, InputSize)], t) -> Dict[str, NDArray]:\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        grads : Dict[str, NDArray] = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100,)\n",
      "(100, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "net = TowLayerNN(input_size=784, hidden_size=100, output_size=10)\n",
    "print(net.params['W1'].shape)\n",
    "print(net.params['b1'].shape)\n",
    "print(net.params['W2'].shape)\n",
    "print(net.params['b2'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100,)\n",
      "(100, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(10, 784)\n",
    "t = np.random.rand(10, 10)\n",
    "grads = net.numerical_gradient(x, t)\n",
    "\n",
    "print(grads['W1'].shape)\n",
    "print(grads['b1'].shape)\n",
    "print(grads['W2'].shape)\n",
    "print(grads['b2'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ミニバッチ学習の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [02:54<00:00, 87.43s/it]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "train_images = train_images.reshape(60000, 784) / 255\n",
    "test_images = test_images.reshape(10000, 784) / 255\n",
    "\n",
    "train_loss_list : List[float] = []\n",
    "train_acc_list : List[float] = []\n",
    "test_acc_list : List[float] = []\n",
    "iters_num = 2\n",
    "train_size = train_images.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "iter_per_epoch : int = int(max(train_size / batch_size, 1))\n",
    "\n",
    "network = TowLayerNN(input_size=784, hidden_size=50, output_size=10)\n",
    "for i in tqdm(range(iters_num)):\n",
    "    batch_mask : NDArray[(batch_size), int] = np.random.choice(train_size, batch_size)\n",
    "    x_batch : NDArray[(batch_size, 784)] = train_images[batch_mask]\n",
    "    t_batch : NDArray[(batch_size, 10)] = train_labels[batch_mask]\n",
    "    grad : Dict[str, NDArray] = network.numerical_gradient(x_batch, t_batch)\n",
    "\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss : float = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc : float = network.accuracy(train_images, train_labels)\n",
    "        test_acc : float = network.accuracy(test_images, test_labels)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "14b7f5b152ecc52abcb0325e148e25eb7ac47fa0fe7451f391c5534b072f0fa5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
